<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Research</title>
  <meta name="author" content="Vlad" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
  integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
  crossorigin="anonymous"></script>
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/main.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/pygment.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/typogrify.css" />
  <link rel="shortcut icon" href="//vene.ro/favicon.ico" />
  <link href="//vene.ro/" type="application/atom+xml"
        rel="alternate" title="Vlad Niculae ALL Atom Feed" />
  <link href="//fonts.googleapis.com/css?family=PT+Mono|PT+Serif" rel="stylesheet"> 

  <meta property="og:type" content="website" />
  <meta property="twitter:creator" content=@vnfrombucharest" />
  <meta name="twitter:card" content="summary">

  <!-- OpenGraph Info -->
  <meta property="og:title" content="Vlad Niculae"/>
  <meta property="og:description" content=""/>
  <meta property="og:url" content="//vene.ro"/>


  <script src="//vene.ro/theme/js/main.js"></script>

</head>

<body>
<div id="container">
<header>
  <nav class="navmenu" id="navmenu">
    <li id="homelink"><a href="/">Vlad Niculae</a>
    </li><li class="menu"><a href="//vene.ro/papers.html">Research</a>
    </li><li class="menu"><a href="//vene.ro/blog/">Blog</a>
    </li><li class="menu"><a href="//vene.ro/teaching.html">Teaching</a>
    </li><li class="menu"><a href="//vene.ro/students.html">Students</a>
   </li>
   </nav>
 </header>
 <div id="main">
<h1 id="my-research">My research<a class="headerlink" href="#my-research" title="Permanent link">&para;</a></h1>
<h2 id="projects">Projects<a class="headerlink" href="#projects" title="Permanent link">&para;</a></h2>
<p>I am currently working on the following funded research&nbsp;projects:</p>
<ul>
<li><span class="caps">NWO</span> <span class="caps">VI</span>.Veni.212.228 &#8220;Rethinking Natural Language Generation: Bridging the Gap Between Discrete and Continuous&nbsp;Representations&#8221;</li>
<li>Horizon Europe 101070631 &#8220;<span class="caps">UTTER</span>: Unified Transcription and Translation for
   Extended&nbsp;Reality&#8221;</li>
<li>Trustworthy <span class="caps">AI</span> for Media (<span class="caps">TAIM</span>)</li>
<li>Hybrid&nbsp;Intelligence</li>
</ul>
<h2 id="publications">Publications<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h2>
<p>(<a href="https://scholar.google.com/citations?user=7_3UAgQAAAAJ">Google Scholar</a>,
<a href="https://www.semanticscholar.org/author/2114966">Semantic Scholar</a>,
<a href="https://aclweb.org/anthology/people/vlad-niculae"><span class="caps">ACL</span> Anthology</a>&nbsp;links.)</p>
<p><em>Book-like things</em>:</p>
<ul>
<li>
<p>Vlad Niculae, Caio F. Corro, Nikita Nangia, Tsvetomila Mihaylova,
Andr√© <span class="caps">F. T.</span> Martins.
<em>Discrete Latent Structure in Neural Networks.</em>
Foundations and Trends¬Æ in Signal Processing 19 (2), 99-211 2025.
[&nbsp;<a href="https://www.nowpublishers.com/article/Details/SIG-134">publisher page</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2301.07473">arXiv&nbsp;preprint</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae.
<em>Learning Deep Models with Linguistically-Inspired Structure.</em>
Doctoral dissertation, Cornell University. 2018.
[&nbsp;<a href="https://doi.org/10.7298/X4SJ1HVQ">open access doi</a>&nbsp;]</p>
</li>
</ul>
<p><em>Preprints</em>:</p>
<ul>
<li>Emmanouil Zaranis, Ant√≥nio Farinhas, Saul Santos, Beatriz Canaverde, Miguel Moura Ramos, [&#8230;], V. Niculae, [&#8230;]
Movie Facts and Fibs (<span class="caps">MF</span><sup>2</sup>): A Benchmark for Long Movie Understanding.
[&nbsp;<a href="https://arxiv.org/abs/2506.06275">arXiv</a>&nbsp;]</li>
</ul>
<!--, Aditya K Surikuchi, Andr√© Viveiros, Baohao Liao, Elena Bueno-Benito, Nithin Sivakumaran, Pavlo Vasylenko, Shoubin Yu, Sonal Sannigrahi, Wafaa Mohammed, Ben Peters, Danae S√°nchez Villegas, Elias Stengel-Eskin, Giuseppe Attanasio, Jaehong Yoon, Stella Frank, Alessandro Suglia, Chrysoula Zerva, Desmond Elliott, Mariella Dimiccoli, Mohit Bansal, Oswald Lanz, Raffaella Bernardi, Raquel Fern√°ndez, Sandro Pezzelle, Vlad Niculae, Andr√© FT Martins.-->

<p><em>Papers</em>:</p>
<ul>
<li>
<p>Evgeniia Tokarchuk, Sergey Troshin, Vlad Niculae.
Angular dispersion accelerates <em>k</em>-nearest neighbors machine translation.
<em><span class="caps">EMNLP</span> Findings, 2025.</em>
(coming&nbsp;soon)</p>
</li>
<li>
<p>Sergey Troshin<em>, Wafaa Mohammed</em>, Yan Meng<em>, Christof Monz,
Antske Fokkens, Vlad Niculae.
Control the temperature: Selective sampling for diverse and
high-quality <span class="caps">LLM</span> outputs.
</em><span class="caps">COLM</span>, 2025*.
[&nbsp;<a href="https://openreview.net/pdf?id=IyOC5GCzv4">pdf</a>&nbsp;]</p>
</li>
<li>
<p>Sergey Troshin, Vlad Niculae, Antske Fokkens.
On the low-rank parametrization of reward models for controlled language generation.
<em><span class="caps">TMLR</span>, 2025.</em>
[&nbsp;<a href="https://openreview.net/pdf?id=cjRsEGLT8B">pdf</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2407.04615">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/serjtroshin/rad-q">code</a>&nbsp;]</p>
</li>
<li>
<p>Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae.
Keep your distance: learning dispersed embeddings on ùïä<sub>m</sub>.
<em><span class="caps">TMLR</span>, 2025.</em>
[&nbsp;<a href="https://openreview.net/pdf?id=5JIQE6HcTd">pdf</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2502.08231">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/ltl-uva/ledoh-torch">code</a>&nbsp;]</p>
</li>
<li>
<p>Wafaa Mohammed, Vlad Niculae.
Context-aware or context-insensitive? Assessing LLMs&#8217; performance in document-level translation.
<em><span class="caps">MT</span> Summit, 2025.</em>
[&nbsp;<a href="https://arxiv.org/abs/2410.14391">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Maya K. Nachesa, Vlad Niculae.
kNN for Whisper and its effect on bias and speaker adaptation.
<em><span class="caps">NAACL</span> Findings, 2025.</em>
[&nbsp;<a href="https://aclanthology.org/2025.findings-naacl.369/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Saul Santos, Vlad Niculae, Daniel McNamee, Andr√© <span class="caps">F. T.</span> Martins.
Sparse and structured Hopfield networks.
<em><span class="caps">ICML</span>, 2024 (Spotlight).</em>
[&nbsp;<a href="https://proceedings.mlr.press/v235/santos24a.html"><span class="caps">PMLR</span></a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2402.13725">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/SSHN">code</a>&nbsp;]</p>
</li>
<li>
<p>Evgeniia Tokarchuk, Vlad Niculae.
The unreasonable effectiveness of random target embeddings for 
continuous-output neural machine translation. 
<em><span class="caps">NAACL</span>, 2024.</em>
[&nbsp;<a href="https://aclanthology.org/2024.naacl-short.56/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2310.20620">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Wafaa Mohammed, Vlad Niculae.
On measuring context utilization in document-level <span class="caps">MT</span> systems.
<em><span class="caps">EACL</span> Findings, 2024</em>.
[&nbsp;<a href="https://aclanthology.org/2024.findings-eacl.113/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2402.01404">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Ali Araabi, Vlad Niculae, Christof Monz.
Entropy‚Äì and Distance-Regularized Attention Improves Low-Resource Neural Machine Translation
<em><span class="caps">AMTA</span>, 2024</em>.
[&nbsp;<a href="https://aclanthology.org/2024.amta-research.13/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Sergey Troshin, Vlad Niculae.
Wrapped Œ≤-Gaussians with compact support for exact probabilistic modeling on manifolds.
<em><span class="caps">TMLR</span> 2023</em>.
[&nbsp;<a href="https://openreview.net/pdf?id=KrequDpWzt">pdf</a>&nbsp;]
[&nbsp;<a href="https://github.com/ltl-uva/wbg">code</a>&nbsp;]
[&nbsp;<a href="https://openreview.net/forum?id=KrequDpWzt">openreview</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae.
Two derivations of Principal Component Analysis on datasets of distributions.
2023.
[&nbsp;<a href="https://arxiv.org/abs/2306.13503">arXiv&nbsp;preprint</a>&nbsp;]</p>
</li>
<li>
<p>Ali Araabi, Vlad Niculae, Christof Monz.
Joint Dropout: Improving generalizability in 
low-resource neural machine translation through phrase pair variables.
<em><span class="caps">MT</span> Summit, 2023</em>.
[&nbsp;<a href="https://aclanthology.org/2023.mtsummit-research.2/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2307.12835">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>David Stap, Vlad Niculae, Christof Monz.
Viewing knowledge transfer in multilingual machine translation
through a representational lens. 
<em><span class="caps">ACL</span> Findings, 2023.</em>
[&nbsp;<a href="https://arxiv.org/abs/2305.11550">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt J Kusner, Vlad Niculae.
<span class="caps">DAG</span> learning on the Permutahedron.
In: <em><span class="caps">ICLR</span> 2023</em>.
[&nbsp;<a href="https://arxiv.org/abs/2301.11898">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Andr√© <span class="caps">F. T.</span> Martins, Marcos Treviso, Ant√≥nio Farinhas, Pedro <span class="caps">M. Q.</span> Aguiar,
M√°rio <span class="caps">A. T.</span> Figueiredo, Mathieu Blondel, Vlad Niculae.
Sparse continuous distributions and Fenchel-Young losses. <em><span class="caps">JMLR</span> 2022</em>.
[&nbsp;<a href="https://www.jmlr.org/papers/v23/21-0879.html">jmlr&nbsp;abs</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/2108.01988">arXiv&nbsp;preprint</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/sparse_continuous_distributions/">code</a>&nbsp;]</p>
</li>
<li>
<p>Ali Araabi, Christof Monz, Vlad Niculae.
How effective is Byte Pair Encoding for out-of-vocabulary words in Neural Machine Translation?
In: <em><span class="caps">AMTA</span> 2022</em>.
[&nbsp;<a href="https://aclanthology.org/2022.amta-research.9/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Evgeniia Tokarchuk, Vlad Niculae.
On target representation in continuous-output Neural Machine Translation.
In: <em>Repl4NLP 2022: Workshop on Representation Learning for <span class="caps">NLP</span></em>.
[&nbsp;<a href="https://aclanthology.org/2022.repl4nlp-1.24">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Valentina Zantedeschi, Jean Kaddour, Luca Franceschi, Matt Kusner, Vlad Niculae.
<span class="caps">DAG</span> learning on the Permutahedron.
In: <em><span class="caps">ICLR</span> 2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality</em>.
[&nbsp;<a href="https://openreview.net/pdf?id=S8X8vS_85gc">pdf</a>&nbsp;]</p>
</li>
<li>
<p>Tsvetomila Mihaylova, Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins.
Modeling structure with Undirected Neural Networks.
In: Proc. of <em><span class="caps">ICML</span> 2022</em>.
[&nbsp;<a href="https://arxiv.org/abs/2202.03760">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Ant√≥nio Farinhas, Wilker Aziz, Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins.
Sparse communication via mixed distributions.
In: Proc. of <em><span class="caps">ICLR</span> 2022</em>.
[&nbsp;<a href="https://arxiv.org/abs/2108.02658">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Valentina Zantedeschi, Matt J. Kusner, Vlad Niculae.
Learning binary trees by argmin differentiation.
In: Proc. of <em><span class="caps">ICML</span> 2021</em> 
[&nbsp;<a href="https://arxiv.org/abs/2010.04627">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/vzantedeschi/LatentTrees">code</a>&nbsp;]</p>
</li>
<li>
<p>Pedro Henrique Martins, Vlad Niculae, Zita Marinho, Andr√© <span class="caps">F. T.</span> Martins.
Sparse and structured visual attention.
In: Proc. of <em><span class="caps">ICIP</span> 2021</em>, <span class="caps">IEEE</span> 
[&nbsp;<a href="https://arxiv.org/abs/2002.05556">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Andr√© <span class="caps">F. T.</span> Martins, Marcos Treviso, Ant√≥nio Farinhas, Vlad Niculae, M√°rio <span class="caps">A.
T.</span> Figueiredo, Pedro <span class="caps">M. Q.</span> Aguiar.
Sparse and Continuous Attention Mechanisms. In: Proc. of <em>NeurIPS 2020</em>
[&nbsp;<a href="https://arxiv.org/abs/2006.07214">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Mathieu Blondel, Andr√© <span class="caps">F. T.</span> Martins, Vlad Niculae.
Learning with Fenchel-Young losses. <span class="caps">JMLR</span> <em>2020</em>.
[&nbsp;<a href="https://arxiv.org/abs/1901.02324">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/mblondel/fenchel-young-losses">code</a>&nbsp;]</p>
</li>
<li>
<p>Tsvetomila Mihaylova, Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins.
Understanding the mechanics of <span class="caps">SPIGOT</span>: Surrogate gradients for latent structure
learning.
In: Proc. of <em><span class="caps">EMNLP</span> 2020</em>. 
[&nbsp;<a href="https://www.aclweb.org/anthology/2020.emnlp-main.171/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Gon√ßalo M. Correia, Vlad Niculae, Wilker Aziz, Andr√© <span class="caps">F. T.</span> Martins.
Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity.
In: Proc. of <em>NeurIPS 2020</em>.
[&nbsp;<a href="https://arxiv.org/abs/2007.01919">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/sparse-marginalization-lvm">code</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae and Andr√© <span class="caps">F. T.</span> Martins.
<em><span class="caps">LP</span>-SparseMAP:</em> Differentiable relaxed optimization for sparse structured
prediction. In: Proc. of <em><span class="caps">ICML</span> 2020</em>
[&nbsp;<a href="https://arxiv.org/abs/2001.04437">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/lp-sparsemap">code</a>&nbsp;]</p>
</li>
<li>
<p>Gon√ßalo M. Correia, Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins.
Adaptively sparse transformers.
In: Proc. of <em><span class="caps">EMNLP</span>-<span class="caps">IJCNLP</span> 2019</em>
[&nbsp;<a href="https://arxiv.org/abs/1909.00015">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/entmax">code</a>&nbsp;]</p>
</li>
<li>
<p>Ben Peters, Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins.
Sparse sequence-to-sequence models.
In: Proc. of <em><span class="caps">ACL</span> 2019</em>. 
[&nbsp;<a href="https://www.aclweb.org/anthology/P19-1146/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/1905.05702">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/deep-spin/entmax">code</a>&nbsp;]</p>
</li>
<li>
<p>Mathieu Blondel, Andr√© <span class="caps">F. T.</span> Martins, Vlad Niculae.
Learning classifiers with Fenchel-Young losses: Generalized entropies, margins,
and algorithms. In: Proc. of <em><span class="caps">AISTATS</span> 2019</em>.
[&nbsp;<a href="https://arxiv.org/abs/1805.09717">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/mblondel/fenchel-young-losses">code</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins, Mathieu Blondel, Claire Cardie.
<em>SparseMAP:</em> Differentiable sparse structured inference.
In: Proc. of <em><span class="caps">ICML</span> 2018</em>.
[&nbsp;<a href="https://arxiv.org/abs/1802.04223">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/vene/sparsemap">code</a>&nbsp;]
[&nbsp;<a href="/talks/sparsemap-icml18-talk.pdf">slides</a>&nbsp;]
[&nbsp;<a href="https://vimeo.com/294661122">video</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Andr√© <span class="caps">F. T.</span> Martins, Claire Cardie.
Towards dynamic computation graphs via sparse latent structure.
In: Proc. of <em><span class="caps">EMNLP</span> 2018</em>.
[&nbsp;<a href="https://aclweb.org/anthology/papers/D/D18/D18-1108/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/1809.00653">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/vene/sparsemap/tree/master/cpp">code</a>&nbsp;]
[&nbsp;<a href="/talks/18-sparsemap-emnlp.pdf">slides</a>&nbsp;]
[&nbsp;<a href="https://vimeo.com/305198410">video</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae and Mathieu Blondel.
A regularized framework for sparse and structured neural attention.
In: Proc. of <em>NeurIPS 2017</em>.
[&nbsp;<a href="https://arxiv.org/abs/1705.07704">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/vene/sparse-structured-attention">code</a>&nbsp;]</p>
</li>
<li>
<p>Mathieu Blondel, Vlad Niculae, Takuma Otsuka, Naonori Ueda.
Multi-output polynomial networks and factorization machines. In: Proc.
of <em>NeurIPS 2017</em>.
[&nbsp;<a href="https://arxiv.org/abs/1705.07603">arXiv</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Joonsuk Park, Claire Cardie.
Argument mining with structured SVMs and RNNs. In: Proc. of <em><span class="caps">ACL</span> 2017</em>.
[&nbsp;<a href="https://aclweb.org/anthology/papers/P/P17/P17-1091/">anthology</a>&nbsp;]
[&nbsp;<a href="https://arxiv.org/abs/1704.06869">arXiv</a>&nbsp;]
[&nbsp;<a href="https://github.com/vene/marseille">code</a>&nbsp;]
[&nbsp;<a href="http://joonsuk.org/">data</a>&nbsp;]
[&nbsp;<a href="https://vimeo.com/234957758">video</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae and Cristian Danescu-Niculescu-Mizil.
Conversational markers of constructive discussions. In: Proc. of <em><span class="caps">NAACL</span>-<span class="caps">HLT</span> 2016</em>.
[&nbsp;<a href="/constructive">website</a>&nbsp;]
[&nbsp;<a href="https://aclweb.org/anthology/papers/N/N16/N16-1070/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, Lillian Lee.
Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions. In: Proc. of <em><span class="caps">WWW</span> 2016</em>.
[&nbsp;<a href="https://chenhaot.com/pages/changemyview.html">website</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Srijan Kumar, Jordan Boyd-Graber, Cristian Danescu-Niculescu-Mizil. Linguistic harbingers of betrayal: A case study
on an online strategy game. In: Proc. of <em><span class="caps">ACL</span> 2015</em>.
[&nbsp;<a href="/betrayal">website</a>&nbsp;]
[&nbsp;<a href="https://aclweb.org/anthology/papers/P/P15/P15-1159/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae*, Caroline Suen*, Justine Zhang*, Cristian Danescu-Niculescu-Mizil, Jure Leskovec. <em><span class="caps">QUOTUS</span>:</em> The structure of political media coverage as revealed by quoting patterns. In: Proc. of <em><span class="caps">WWW</span> 2015</em>.
[&nbsp;<a href="http://snap.stanford.edu/quotus/">website</a>&nbsp;]
[&nbsp;<a href="papers/quotus-talk-vlad-web.pdf">slides</a>&nbsp;]</p>
</li>
<li>
<p>Marcos Zampieri, Alina Maria Ciobanu, Vlad Niculae, Liviu P. Dinu.
<em><span class="caps">AMBRA</span>:</em> A ranking approach to temporal text classification.
In: Proc. of <em>Semeval 2015</em>.
[&nbsp;<a href="https://aclweb.org/anthology/papers/S/S15/S15-2144/">anthology</a>&nbsp;]
[&nbsp;<a href="http://github.com/vene/ambra">code</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae and Cristian Danescu-Niculescu-Mizil.
<em>Brighter than Gold:</em> Figurative language in user generated comparisons.
In: Proc. of <em><span class="caps">EMNLP</span> 2014</em>.
[&nbsp;<a href="/figurative-comparisons">website</a>&nbsp;]
[&nbsp;<a href="https://www.aclweb.org/anthology/D14-1215/">anthology</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, Alina Maria Ciobanu.
Temporal text ranking and automatic dating of texts. In: Proc. of <em><span class="caps">EACL</span> 2014</em>.
[&nbsp;<a href="https://aclweb.org/anthology/papers/W/W13/W13-2714/">anthology</a>&nbsp;]
[ <a href="papers/eacl14-temporal-slides.pdf">&nbsp;slides&nbsp;</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae. Comparison pattern matching and creative simile recognition. In:
Proc. of <em><span class="caps">JSSP</span> 2013</em>.
[&nbsp;<a href="http://aclweb.org/anthology/W/W13/W13-3829/">anthology</a>&nbsp;]
[&nbsp;<a href="papers/jssp13-similes-poster.pdf">poster</a>&nbsp;]
[&nbsp;<a href="https://github.com/vene/comparison-pattern">code</a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae and Octavian Popescu. Determining <em>is-a</em> relationships for textual
entailment. In: Proc. of <em><span class="caps">JSSP</span> 2013</em>.
[&nbsp;<a href="http://aclweb.org/anthology/W/W13/W13-3830.pdf">anthology</a>&nbsp;]
[&nbsp;<a href="papers/jssp-rte-poster.pdf">poster</a>&nbsp;]</p>
</li>
<li>
<p>Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas
M√ºller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort,
Jaques Grobler, Robert Layton, Jake Vanderplas, Arnaud Joly, Brian Holt and
Ga√´l Varoquaux.
<span class="caps">API</span> design for machine learning software: experiences from the scikit-learn
project.  In: <em><span class="caps">ECML</span>/<span class="caps">PKDD</span> 2013 Workshop: Languages for Data Mining and Machine
Learning</em>.
[&nbsp;<a href="http://orbi.ulg.ac.be/bitstream/2268/154357/1/paper.pdf"><span class="caps">PDF</span></a>&nbsp;]</p>
</li>
<li>
<p>Vlad Niculae, Victoria Yaneva,
Computational considerations of comparisons and similes. In: <em>Proceedings of <span class="caps">ACL</span>
Student Research Workshop</em>, 2013.
[&nbsp;<a href="https://aclweb.org/anthology/papers/P/P13/P13-3013/">anthology</a>&nbsp;] 
[&nbsp;<a href="papers/aclsrw13-poster.pdf">poster</a>&nbsp;]</p>
</li>
</ul>
 </div>
<footer>
  <p>Powered by <a href="http://pelican.readthedocs.org">Pelican</a>.
  <a href="/privacy.html">Privacy policy</a>.</p>
</footer>
</div>
</body>
</html>