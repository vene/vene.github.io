Title: Research
Slug: papers

# My research

## Projects
I am currently working on the following funded research projects:

 - NWO VI.Veni.212.228 ``Rethinking Natural Language Generation: Bridging the Gap Between Discrete and Continuous Representations''
 - Horizon Europe 101070631 ``UTTER: Unified Transcription and Translation for
   Extended Reality''
 - Trustworthy AI for Media (TAIM)
 - Hybrid Intelligence

## Publications

([Google Scholar](https://scholar.google.com/citations?user=7_3UAgQAAAAJ),
[Semantic Scholar](https://www.semanticscholar.org/author/2114966),
[ACL Anthology](https://aclweb.org/anthology/people/vlad-niculae) links.)

*Book-like things*:

* Vlad Niculae, Caio F. Corro, Nikita Nangia, Tsvetomila Mihaylova,
Andr√© F. T. Martins.
*Discrete Latent Structure in Neural Networks.*
Foundations and Trends¬Æ in Signal Processing 19 (2), 99-211 2025.
\[&nbsp;[publisher page](https://www.nowpublishers.com/article/Details/SIG-134)&nbsp;\]
\[&nbsp;[arXiv&nbsp;preprint](https://arxiv.org/abs/2301.07473)&nbsp;\]

* Vlad Niculae.
*Learning Deep Models with Linguistically-Inspired Structure.*
Doctoral dissertation, Cornell University. 2018.
\[&nbsp;[open access doi](https://doi.org/10.7298/X4SJ1HVQ)&nbsp;\]

*Preprints*:

* Emmanouil Zaranis, Ant√≥nio Farinhas, Saul Santos, Beatriz Canaverde, Miguel Moura Ramos, [...], V. Niculae, [...]
Movie Facts and Fibs (MF<sup>2</sup>): A Benchmark for Long Movie Understanding.
\[&nbsp;[arXiv](https://arxiv.org/abs/2506.06275)&nbsp;\]
<!--, Aditya K Surikuchi, Andr√© Viveiros, Baohao Liao, Elena Bueno-Benito, Nithin Sivakumaran, Pavlo Vasylenko, Shoubin Yu, Sonal Sannigrahi, Wafaa Mohammed, Ben Peters, Danae S√°nchez Villegas, Elias Stengel-Eskin, Giuseppe Attanasio, Jaehong Yoon, Stella Frank, Alessandro Suglia, Chrysoula Zerva, Desmond Elliott, Mariella Dimiccoli, Mohit Bansal, Oswald Lanz, Raffaella Bernardi, Raquel Fern√°ndez, Sandro Pezzelle, Vlad Niculae, Andr√© FT Martins.-->


*Papers*:

* Wafaa Mohammed, Vlad Niculae, Chrysoula Zerva.
Unlocking Latent Discourse Translation in LLMs Through Quality-Aware Decoding.
*EACL, 2026*.

* Evgeniia Tokarchuk, Maya Nachesa, Sergey Troshin, Vlad Niculae.
Representation Collapse in Machine Translation Through the Lens of Angular Dispersion
*EACL Findings, 2026.*

* Evgeniia Tokarchuk, Sergey Troshin, Vlad Niculae.
Angular dispersion accelerates *k*-nearest neighbors machine translation.
*EMNLP Findings, 2025.*
\[&nbsp;[anthology](https://aclanthology.org/2025.findings-emnlp.759/)&nbsp;\]

* Sergey Troshin,\* Wafaa Mohammed,\* Yan Meng,\* Christof Monz,
Antske Fokkens, Vlad Niculae.
Control the temperature: Selective sampling for diverse and
high-quality LLM outputs.
*COLM, 2025*.
\[&nbsp;[pdf](https://openreview.net/pdf?id=IyOC5GCzv4)&nbsp;\]

* Sergey Troshin, Vlad Niculae, Antske Fokkens.
On the low-rank parametrization of reward models for controlled language generation.
*TMLR, 2025.*
\[&nbsp;[pdf](https://openreview.net/pdf?id=cjRsEGLT8B)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2407.04615)&nbsp;\]
\[&nbsp;[code](https://github.com/serjtroshin/rad-q)&nbsp;\]

* Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae.
Keep your distance: learning dispersed embeddings on ùïä<sub>m</sub>.
*TMLR, 2025.*
\[&nbsp;[pdf](https://openreview.net/pdf?id=5JIQE6HcTd)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2502.08231)&nbsp;\]
\[&nbsp;[code](https://github.com/ltl-uva/ledoh-torch)&nbsp;\]

* Wafaa Mohammed, Vlad Niculae.
Context-aware or context-insensitive? Assessing LLMs' performance in document-level translation.
*MT Summit, 2025.*
\[&nbsp;[arXiv](https://arxiv.org/abs/2410.14391)&nbsp;\]

* Maya K. Nachesa, Vlad Niculae.
kNN for Whisper and its effect on bias and speaker adaptation.
*NAACL Findings, 2025.*
\[&nbsp;[anthology](https://aclanthology.org/2025.findings-naacl.369/)&nbsp;\]

* Saul Santos, Vlad Niculae, Daniel McNamee, Andr√© F. T. Martins.
Sparse and structured Hopfield networks.
*ICML, 2024 (Spotlight).*
\[&nbsp;[PMLR](https://proceedings.mlr.press/v235/santos24a.html)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2402.13725)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/SSHN)&nbsp;\]

* Evgeniia Tokarchuk, Vlad Niculae.
The unreasonable effectiveness of random target embeddings for 
continuous-output neural machine translation. 
*NAACL, 2024.*
\[&nbsp;[anthology](https://aclanthology.org/2024.naacl-short.56/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2310.20620)&nbsp;\]

* Wafaa Mohammed, Vlad Niculae.
On measuring context utilization in document-level MT systems.
*EACL Findings, 2024*.
\[&nbsp;[anthology](https://aclanthology.org/2024.findings-eacl.113/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2402.01404)&nbsp;\]

* Ali Araabi, Vlad Niculae, Christof Monz.
Entropy‚Äì and Distance-Regularized Attention Improves Low-Resource Neural Machine Translation
*AMTA, 2024*.
\[&nbsp;[anthology](https://aclanthology.org/2024.amta-research.13/)&nbsp;\]

* Sergey Troshin, Vlad Niculae.
Wrapped Œ≤-Gaussians with compact support for exact probabilistic modeling on manifolds.
*TMLR 2023*.
\[&nbsp;[pdf](https://openreview.net/pdf?id=KrequDpWzt)&nbsp;\]
\[&nbsp;[code](https://github.com/ltl-uva/wbg)&nbsp;\]
\[&nbsp;[openreview](https://openreview.net/forum?id=KrequDpWzt)&nbsp;\]

* Vlad Niculae.
Two derivations of Principal Component Analysis on datasets of distributions.
2023.
\[&nbsp;[arXiv&nbsp;preprint](https://arxiv.org/abs/2306.13503)&nbsp;\]

* Ali Araabi, Vlad Niculae, Christof Monz.
Joint Dropout: Improving generalizability in 
low-resource neural machine translation through phrase pair variables.
*MT Summit, 2023*.
\[&nbsp;[anthology](https://aclanthology.org/2023.mtsummit-research.2/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/2307.12835)&nbsp;\]

* David Stap, Vlad Niculae, Christof Monz.
Viewing knowledge transfer in multilingual machine translation
through a representational lens. 
*ACL Findings, 2023.*
\[&nbsp;[arXiv](https://arxiv.org/abs/2305.11550)&nbsp;\]

* Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt J Kusner, Vlad Niculae.
DAG learning on the Permutahedron.
In: *ICLR 2023*.
\[&nbsp;[arXiv](https://arxiv.org/abs/2301.11898)&nbsp;\]

* Andr√© F. T. Martins, Marcos Treviso, Ant√≥nio Farinhas, Pedro M. Q. Aguiar,
M√°rio A. T. Figueiredo, Mathieu Blondel, Vlad Niculae.
Sparse continuous distributions and Fenchel-Young losses. *JMLR 2022*.
\[&nbsp;[jmlr&nbsp;abs](https://www.jmlr.org/papers/v23/21-0879.html)&nbsp;\]
\[&nbsp;[arXiv&nbsp;preprint](https://arxiv.org/abs/2108.01988)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/sparse_continuous_distributions/)&nbsp;\]

* Ali Araabi, Christof Monz, Vlad Niculae.
How effective is Byte Pair Encoding for out-of-vocabulary words in Neural Machine Translation?
In: *AMTA 2022*.
\[&nbsp;[anthology](https://aclanthology.org/2022.amta-research.9/)&nbsp;]

* Evgeniia Tokarchuk, Vlad Niculae.
On target representation in continuous-output Neural Machine Translation.
In: *Repl4NLP 2022: Workshop on Representation Learning for NLP*.
\[&nbsp;[anthology](https://aclanthology.org/2022.repl4nlp-1.24)&nbsp;\]

* Valentina Zantedeschi, Jean Kaddour, Luca Franceschi, Matt Kusner, Vlad Niculae.
DAG learning on the Permutahedron.
In: *ICLR 2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality*.
\[&nbsp;[pdf](https://openreview.net/pdf?id=S8X8vS_85gc)&nbsp;\]

* Tsvetomila Mihaylova, Vlad Niculae, Andr√© F. T. Martins.
Modeling structure with Undirected Neural Networks.
In: Proc. of *ICML 2022*.
\[&nbsp;[arXiv](https://arxiv.org/abs/2202.03760)&nbsp;\]

*  Ant√≥nio Farinhas, Wilker Aziz, Vlad Niculae, Andr√© F. T. Martins.
Sparse communication via mixed distributions.
In: Proc. of *ICLR 2022*.
\[&nbsp;[arXiv](https://arxiv.org/abs/2108.02658)&nbsp;\]

* Valentina Zantedeschi, Matt J. Kusner, Vlad Niculae.
Learning binary trees by argmin differentiation.
In: Proc. of *ICML 2021* 
\[&nbsp;[arXiv](https://arxiv.org/abs/2010.04627)&nbsp;\]
\[&nbsp;[code](https://github.com/vzantedeschi/LatentTrees)&nbsp;\]

* Pedro Henrique Martins, Vlad Niculae, Zita Marinho, Andr√© F. T. Martins.
Sparse and structured visual attention.
In: Proc. of *ICIP 2021*, IEEE 
\[&nbsp;[arXiv](https://arxiv.org/abs/2002.05556)&nbsp;\]

* Andr√© F. T. Martins, Marcos Treviso, Ant√≥nio Farinhas, Vlad Niculae, M√°rio A.
T. Figueiredo, Pedro M. Q. Aguiar.
Sparse and Continuous Attention Mechanisms. In: Proc. of *NeurIPS 2020*
\[&nbsp;[arXiv](https://arxiv.org/abs/2006.07214)&nbsp;\]

* Mathieu Blondel, Andr√© F. T. Martins, Vlad Niculae.
Learning with Fenchel-Young losses. JMLR *2020*.
\[&nbsp;[arXiv](https://arxiv.org/abs/1901.02324)&nbsp;\]
\[&nbsp;[code](https://github.com/mblondel/fenchel-young-losses)&nbsp;\]

* Tsvetomila Mihaylova, Vlad Niculae, Andr√© F. T. Martins.
Understanding the mechanics of SPIGOT: Surrogate gradients for latent structure
learning.
In: Proc. of *EMNLP 2020*. 
\[&nbsp;[anthology](https://www.aclweb.org/anthology/2020.emnlp-main.171/)&nbsp;\]

* Gon√ßalo M. Correia, Vlad Niculae, Wilker Aziz, Andr√© F. T. Martins.
Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity.
In: Proc. of *NeurIPS 2020*.
\[&nbsp;[arXiv](https://arxiv.org/abs/2007.01919)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/sparse-marginalization-lvm)&nbsp;\]

* Vlad Niculae and Andr√© F. T. Martins.
*LP-SparseMAP:* Differentiable relaxed optimization for sparse structured
prediction. In: Proc. of *ICML 2020*
\[&nbsp;[arXiv](https://arxiv.org/abs/2001.04437)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/lp-sparsemap)&nbsp;\]

* Gon√ßalo M. Correia, Vlad Niculae, Andr√© F. T. Martins.
Adaptively sparse transformers.
In: Proc. of *EMNLP-IJCNLP 2019*
\[&nbsp;[arXiv](https://arxiv.org/abs/1909.00015)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/entmax)&nbsp;\]

* Ben Peters, Vlad Niculae, Andr√© F. T. Martins.
Sparse sequence-to-sequence models.
In: Proc. of *ACL 2019*. 
\[&nbsp;[anthology](https://www.aclweb.org/anthology/P19-1146/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/1905.05702)&nbsp;\]
\[&nbsp;[code](https://github.com/deep-spin/entmax)&nbsp;\]


* Mathieu Blondel, Andr√© F. T. Martins, Vlad Niculae.
Learning classifiers with Fenchel-Young losses: Generalized entropies, margins,
and algorithms. In: Proc. of *AISTATS 2019*.
\[&nbsp;[arXiv](https://arxiv.org/abs/1805.09717)&nbsp;\]
\[&nbsp;[code](https://github.com/mblondel/fenchel-young-losses)&nbsp;\]


* Vlad Niculae, Andr√© F. T. Martins, Mathieu Blondel, Claire Cardie.
*SparseMAP:* Differentiable sparse structured inference.
In: Proc. of *ICML 2018*.
\[&nbsp;[arXiv](https://arxiv.org/abs/1802.04223)&nbsp;\]
\[&nbsp;[code](https://github.com/vene/sparsemap)&nbsp;\]
\[&nbsp;[slides](/talks/sparsemap-icml18-talk.pdf)&nbsp;\]
\[&nbsp;[video](https://vimeo.com/294661122)&nbsp;\]

* Vlad Niculae, Andr√© F. T. Martins, Claire Cardie.
Towards dynamic computation graphs via sparse latent structure.
In: Proc. of *EMNLP 2018*.
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/D/D18/D18-1108/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/1809.00653)&nbsp;\]
\[&nbsp;[code](https://github.com/vene/sparsemap/tree/master/cpp)&nbsp;\]
\[&nbsp;[slides](/talks/18-sparsemap-emnlp.pdf)&nbsp;\]
\[&nbsp;[video](https://vimeo.com/305198410)&nbsp;\]

* Vlad Niculae and Mathieu Blondel.
A regularized framework for sparse and structured neural attention.
In: Proc. of *NeurIPS 2017*.
\[&nbsp;[arXiv](https://arxiv.org/abs/1705.07704)&nbsp;\]
\[&nbsp;[code](https://github.com/vene/sparse-structured-attention)&nbsp;\]


* Mathieu Blondel, Vlad Niculae, Takuma Otsuka, Naonori Ueda.
Multi-output polynomial networks and factorization machines. In: Proc.
of *NeurIPS 2017*.
\[&nbsp;[arXiv](https://arxiv.org/abs/1705.07603)&nbsp;\]

* Vlad Niculae, Joonsuk Park, Claire Cardie.
Argument mining with structured SVMs and RNNs. In: Proc. of *ACL 2017*.
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/P/P17/P17-1091/)&nbsp;\]
\[&nbsp;[arXiv](https://arxiv.org/abs/1704.06869)&nbsp;\]
\[&nbsp;[code](https://github.com/vene/marseille)&nbsp;\]
\[&nbsp;[data](http://joonsuk.org/)&nbsp;\]
\[&nbsp;[video](https://vimeo.com/234957758)&nbsp;\]


* Vlad Niculae and Cristian Danescu-Niculescu-Mizil.
Conversational markers of constructive discussions. In: Proc. of *NAACL-HLT 2016*.
\[&nbsp;[website](/constructive)&nbsp;\]
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/N/N16/N16-1070/)&nbsp;\]

* Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, Lillian Lee.
Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions. In: Proc. of *WWW 2016*.
\[&nbsp;[website](https://chenhaot.com/pages/changemyview.html)&nbsp;\]

* Vlad Niculae, Srijan Kumar, Jordan Boyd-Graber, Cristian Danescu-Niculescu-Mizil. Linguistic harbingers of betrayal: A case study
on an online strategy game. In: Proc. of *ACL 2015*.
\[&nbsp;[website](/betrayal)&nbsp;\]
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/P/P15/P15-1159/)&nbsp;\]

* Vlad Niculae\*, Caroline Suen\*, Justine Zhang\*, Cristian Danescu-Niculescu-Mizil, Jure Leskovec. *QUOTUS:* The structure of political media coverage as revealed by quoting patterns. In: Proc. of *WWW 2015*.
\[&nbsp;[website](http://snap.stanford.edu/quotus/)&nbsp;\]
\[&nbsp;[slides](papers/quotus-talk-vlad-web.pdf)&nbsp;\]

* Marcos Zampieri, Alina Maria Ciobanu, Vlad Niculae, Liviu P. Dinu.
*AMBRA:* A ranking approach to temporal text classification.
In: Proc. of *Semeval 2015*.
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/S/S15/S15-2144/)&nbsp;]
\[&nbsp;[code](http://github.com/vene/ambra)&nbsp;\]

* Vlad Niculae and Cristian Danescu-Niculescu-Mizil.
*Brighter than Gold:* Figurative language in user generated comparisons.
In: Proc. of *EMNLP 2014*.
\[&nbsp;[website](/figurative-comparisons)&nbsp;\]
\[&nbsp;[anthology](https://www.aclweb.org/anthology/D14-1215/)&nbsp;\]

* Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, Alina Maria Ciobanu.
Temporal text ranking and automatic dating of texts. In: Proc. of *EACL 2014*.
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/W/W13/W13-2714/)&nbsp;\]
\[ [&nbsp;slides&nbsp;](papers/eacl14-temporal-slides.pdf) \]

* Vlad Niculae. Comparison pattern matching and creative simile recognition. In:
Proc. of *JSSP 2013*.
\[&nbsp;[anthology](http://aclweb.org/anthology/W/W13/W13-3829/)&nbsp;\]
\[&nbsp;[poster](papers/jssp13-similes-poster.pdf)&nbsp;\]
\[&nbsp;[code](https://github.com/vene/comparison-pattern)&nbsp;\]

* Vlad Niculae and Octavian Popescu. Determining *is-a* relationships for textual
entailment. In: Proc. of *JSSP 2013*.
\[&nbsp;[anthology](http://aclweb.org/anthology/W/W13/W13-3830.pdf)&nbsp;\]
\[&nbsp;[poster](papers/jssp-rte-poster.pdf)&nbsp;\]

* Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas
M√ºller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort,
Jaques Grobler, Robert Layton, Jake Vanderplas, Arnaud Joly, Brian Holt and
Ga√´l Varoquaux.
API design for machine learning software: experiences from the scikit-learn
project.  In: *ECML/PKDD 2013 Workshop: Languages for Data Mining and Machine
Learning*.
\[&nbsp;[PDF](http://orbi.ulg.ac.be/bitstream/2268/154357/1/paper.pdf)&nbsp;\]

* Vlad Niculae, Victoria Yaneva,
Computational considerations of comparisons and similes. In: *Proceedings of ACL
Student Research Workshop*, 2013.
\[&nbsp;[anthology](https://aclweb.org/anthology/papers/P/P13/P13-3013/)&nbsp;\] 
\[&nbsp;[poster](papers/aclsrw13-poster.pdf)&nbsp;\]
