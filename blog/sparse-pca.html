<!DOCTYPE html>
<html lang="en">
<head>
        <title>Sparse PCA</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="http://vene.ro/theme/css/main.css" type="text/css" />
                <link href="http://vene.ro/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Vlad Niculae (~vene) Atom Feed" />
                        <link href="http://vene.ro/feed/all.rss.xml" type="application/rss+xml" rel="alternate" title="Vlad Niculae (~vene) RSS Feed" />
                <link href='http://fonts.googleapis.com/css?family=Averia+Gruesa+Libre|Alegreya:400italic,400,700|Alegreya+SC&subset=latin-ext' rel='stylesheet' type='text/css'>

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://vene.ro/css/ie.css"/>
                <script src="http://vene.ro/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://vene.ro/css/ie6.css"/><![endif]-->
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
      },
      displayAlign: 'left', // Change this to 'center' to center equations.
      "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
      }
    });
    </script>
    <!-- End of mathjax configuration -->

    <script>
    //  We wait for the onload function to load MathJax after the page is completely loaded.
    //  MathJax is loaded 1 unit of time after the page is ready.
    //  This hack prevent problems when you load multiple js files.

    window.onload = function () {
      setTimeout(function () {
        var script = document.createElement("script");
        script.type = "text/javascript";
        script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS_HTML";
        document.getElementsByTagName("head")[0].appendChild(script);
      },1)
    }
    </script>

</head>

<body id="index" class="home">
<div id="container">
        <header id="banner" class="body">
                <div id="header">Vlad Niculae (~vene)</div>
                <!--<nav><ul>
                                                    <li><a href="http://vene.ro/fonts.html">Fonts</a></li>
                                    <li><a href="http://vene.ro/papers.html">Publications</a></li>
                                    <li><a href="http://vene.ro/talks.html">Talks</a></li>
                                    <li><a href="http://vene.ro/teaching.html">Teaching</a></li>
                                                                    <li><a href="/publications.html">Publications</a></li>
                                    <li><a href="http://vene.ro/blog/">Blog</a></li>
                                                </ul></nav> -->
        </header><!-- /#banner -->
        <div id="main" role="main">
        <section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="http://vene.ro/blog/sparse-pca.html" rel="bookmark"
           title="Permalink to Sparse PCA">Sparse&nbsp;<span class="caps">PCA</span></a></h1>
          </header>

    <div class="entry-content">
      <footer class="post-info">
        <abbr class="published" title="2011-05-23T15:19:00">
                Mon 23 May 2011
        </abbr>

                <address class="vcard author">
                By <a class="url fn" href="http://vene.ro/blog/author/vene.html">vene</a>
        </address>
        <p>In <a href="http://vene.ro/blog/category/scikit-learn.html">scikit-learn</a>. </p>
<p>tags: <a href="http://vene.ro/blog/tag/dictionary-learning.html">dictionary learning</a> <a href="http://vene.ro/blog/tag/pca.html">pca</a> <a href="http://vene.ro/blog/tag/sparse-pca.html">sparse pca</a> <a href="http://vene.ro/blog/tag/sparsepca.html">SparsePCA</a> <a href="http://vene.ro/blog/tag/spca.html">spca</a> <a href="http://vene.ro/blog/tag/scikit-learn.html">scikit-learn</a> </p>
</footer><!-- /.post-info -->      <p>I have been working on the integration into the scikits.learn codebase
of a sparse principal components analysis (SparsePCA) algorithm coded by
Gaël and Alexandre and based on [[1]][]. Because the name &#8220;sparse <span class="caps">PCA</span>&#8221;
has some inherent ambiguity, I will describe in greater depth what
problem we are actually solving, and what it can be used&nbsp;for.</p>
<h1>The&nbsp;problem</h1>
<p>Mathematically, this implementation of Sparse <span class="caps">PCA</span>&nbsp;solves:</p>
<p>\$latex (U\^*,&nbsp;V\^*)=\underset{U,V}{\mathrm{argmin\,}}\frac{1}{2}||X-<span class="caps">UV</span>||_2\^2+\alpha||V||_1\$</p>
<p>with \$latex || U_k ||_2 = 1\$ for all \$latex 0 \leq k \&lt;&nbsp;n_{atoms}\$</p>
<p>This looks really abstract so let&#8217;s try to interpret it. We are looking
for a matrix factorization \$latex <span class="caps">UV</span>\$ of \$latex X \in
\mathbf{R}\^{n_{samples}\times n_{features}}\$, just like in
ordinary <span class="caps">PCA</span>. The interpretation is that the \$latex n_{atoms}\$ lines
of \$latex V\$ are the extracted components, while the lines of \$latex
U\$ are the coordinates of the samples in this&nbsp;projection.</p>
<p>The most important difference between this and <span class="caps">PCA</span> is that we enforce
sparsity on the <em>components</em>. In other words, we look for a
representation of the data as a linear combination of sparse&nbsp;signals.</p>
<p>Another difference is that, unlike in <span class="caps">PCA</span>, here we don&#8217;t constrain U to
be orthogonal, just to consist of normalized column vectors. There are
different approaches where this constraint appears too, and they are on
the list for this summer, but I&nbsp;digress.</p>
<h1>The&nbsp;approach</h1>
<p>As usual, such optimization problems are solved by alternatively
minimizing one of the variables while keeping the other fixed, until
convergence is&nbsp;reached.</p>
<p>The update of \$latex V\$ (the dictionary) is computed as the solution
of a Lasso least squares problem.  We allow the user to choose between
the least angle regression method (<span class="caps">LARS</span>) or stochastic gradient descent
as algorithms to solve the Lasso&nbsp;problem.</p>
<p>The update of \$latex U\$ is block coordinate descent with warm restart.
This is a batch adaptation of an online algorithm proposed by Mairal et
al. in&nbsp;[[1]][].</p>
<h1>Sparse <span class="caps">PCA</span> as a&nbsp;transformer</h1>
<p>Of course, in order to be of practical use, the code needs to be
refactored into a scikits.learn transformer object, just like
<code>scikits.learn.decomposition.pca</code>. This means that the optimization
problem described above corresponds to the fitting stage. The post-fit
state of the transformer is given by the learned components (the matrix
\$latex V\$&nbsp;above).</p>
<p>In order to transform new data according to the learned sparse <span class="caps">PCA</span> model
(for example, prior to classification of the test data), we simply need
to do a least squares projection of the new data on the sparse&nbsp;components.</p>
<h1>What is it good&nbsp;for?</h1>
<p>For applications such as text and image processing, its great advantage
is interpretability. When running a regular <span class="caps">PCA</span> on a set of documents in
bag of words format, we can find an interesting visualisation on a
couple of components, and it can show discrimination or clusters. The
biggest problem is that the maximum variance components found by <span class="caps">PCA</span>
have very dense expressions as linear combinations of the initial
features. In practice, sometimes interpretation is made by simply
marking the \$latex k\$ variables with the highest coefficients in this
representation, and basically interpreting as if the rest are truncated
to 0 (this has been taught to me in a class on <span class="caps">PCA</span>&nbsp;interpretation).</p>
<p>Such an approximation can be highly misleading, and now we offer you the
sparse <span class="caps">PCA</span> code that can extract components with only few non-zero
coefficients, and therefore easy to&nbsp;interpret.</p>
<p>For image data, sparse <span class="caps">PCA</span> should extract local components such as,
famously, parts of the face in the case of face&nbsp;recognition.</p>
<p>Personally I can&#8217;t wait to have it ready for the scikit so that I can
play with it in some of my projects. I have two tasks where I can&#8217;t wait
to see the results: one is related to <a href="http://venefrombucharest.wordpress.com/2011/04/14/a-look-at-romanian-verbs-with-scikits-learn/" title="A look at Romanian verbs with scikits-learn">Romanian infinitives</a>, where
<span class="caps">PCA</span> revealed structure, and I would love to see how it looks with sparse
n-gram components. The other task is to plug it in as feature extractor
for handwritten digit classification, for my undergraduate&nbsp;thesis.</p>
<p><span id="footnote_1">[1] <a href="http://www.di.ens.fr/sierra/pdfs/icml09.pdf">http://www.di.ens.fr/sierra/pdfs/icml09.pdf</a></span></p>
<p>[[1]]:&nbsp;#footnote_1</p>
    </div><!-- /.entry-content -->
        <div class="comments">
      <h2>Comments !</h2>
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        var disqus_identifier = "blog/sparse-pca.html";
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://vene.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
    
  </article>
</section>
        <section id="extras" class="body">
                        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Go <a href="/">home</a>. 
                Powered by <a href="http://getpelican.com/">Pelican</a>
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
        </div>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-47024389-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
<script type="text/javascript">
    var disqus_shortname = 'vene';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</div>
</body>
</html>