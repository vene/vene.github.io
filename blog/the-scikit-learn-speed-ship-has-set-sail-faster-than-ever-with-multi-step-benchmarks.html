<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The scikit-learn-speed ship has set sail! Faster than ever, with multi-step benchmarks!</title>
  <meta name="author" content="Vlad" />
  <base href="//vene.ro">
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/main.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/pygment.css" />
  <link rel="stylesheet" type="text/css" 
        href="//vene.ro/theme/css/typogrify.css" />
  <link rel="shortcut icon" href="//vene.ro/favicon.ico" />
  <link href="//vene.ro/" type="application/atom+xml"
        rel="alternate" title="Vlad Niculae ALL Atom Feed" />
  <link href="//fonts.googleapis.com/css?family=PT+Mono|PT+Serif" rel="stylesheet"> 

  <!-- OpenGraph Info -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      displayAlign: 'left',
      TeX: {
        Macros: {
          RR: "{\\mathbb{R}}",
          argmin: "{\\mathop{\\mathrm{arg\\,min}}}",
          bold: ["{\\bf #1}",1]
        }
        },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>

  <script type="text/javascript" async
          src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

</head>

<body>
<div id="container">
<header>
  <nav class="navmenu" id="navmenu">
    <li id="homelink"><a href="/">Vlad Niculae</a>
    </li><li class="menu"><a href="//vene.ro/papers.html">Papers</a>
    </li><li class="menu"><a href="//vene.ro/blog/">Blog</a>
    </li><li class="menu"><a href="//vene.ro/teaching.html">Teaching</a>
   </li>
   </nav>
 </header>
 <div id="main">
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="//vene.ro/blog/the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks.html" rel="bookmark"
           title="Permalink to The scikit-learn-speed ship has set sail! Faster than ever, with multi-step benchmarks!">The scikit-learn-speed ship has set sail! Faster than ever, with multi-step&nbsp;benchmarks!</a></h1>
<p class="subtitle"><time datetime="2012-08-11T17:32:00+02:00">Sat, 11 Aug 2012</time><label for="the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks" class="margin-toggle"> ⊕</label><input type="checkbox" id="the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks" class="margin-toggle" /><span class="marginnote">Category: <a href="//vene.ro/category/scikit-learn.html">scikit-learn</a><br />
 #<a href="//vene.ro/tag/multi-step.html">multi-step</a> #<a href="//vene.ro/tag/multistep.html">multistep</a> #<a href="//vene.ro/tag/vbench.html">vbench</a> #<a href="//vene.ro/tag/benchmarking.html">benchmarking</a> #<a href="//vene.ro/tag/python.html">python</a> #<a href="//vene.ro/tag/scikit-learn.html">scikit-learn</a></span></p>    </header>

    <div class="entry-content">
      <p>I am pleased to announce that last night at 2:03 <span class="caps">AM</span>, the first fully
automated run of the scikit-learn-speed test suite has run on our
Jenkins instance! You can admire it at <a href="http://jenkins-scikit-learn.github.com/scikit-learn-speed/">its temporary home</a> for now.
As soon as we verify that everything is good, we will move this to the
official scikit-learn&nbsp;page.</p>
<p>I would like to take this opportunity to tell you about our latest
changeset. We made running the benchmark suite tons simpler by adding a
friendly Makefile. You can read more about its usage in the guide. But
by far, our coolest new toy&nbsp;is:</p>
<h2>Multi-step&nbsp;benchmarks</h2>
<p>A standard vbench benchmark has three units of code, represented as
strings: <code>code</code>, <code>setup</code> and <code>cleanup</code>. With the original timeit-based
benchmarks, this means that for every run, the setup would be executed
once. Then, the main loop runs <code>repeat</code> times, and within each
iteration, the <code>code</code> is run <code>ncalls</code> times. Then <code>cleanup</code> happens, the
best time is returned, and everybody is&nbsp;happy.</p>
<p>In scikit-learn, most of our interesting objects go through a state
change called <em>fitting</em>. This metaphor is right at home in the machine
learning field, where we separate the learning phase for the prediction
phase. The prediction step cannot be invoked on an object that hasn&#8217;t
been&nbsp;fitted.</p>
<p>For some algorithms, one of these steps is trivial. A brute force
Nearest Neighbors classifier can be instantaneously fit, but prediction
takes a while. On the opposite end we have linear models, with tons of
complicated algorithms to fit them, but evaluation is a simple
matrix-vector product that Numpy handles&nbsp;perfectly.</p>
<p>But many of scikit-learn&#8217;s estimators have both steps interesting. Let&#8217;s
take Non-negative Matrix Factorization. It has three interesting
functions: The <code>fit</code> that computes \$latex X = <span class="caps">WH</span> \$, the <code>transform</code>
that computes a non-negative projection on the components learned in
<code>fit</code>, and <code>fit_transform</code> that takes advantage of the observation that
when fitting, we also get the transformed \$latex X \$ for&nbsp;free.</p>
<p>When benchmarking <span class="caps">NMF</span>, we initially had to design 3&nbsp;benchmarks:</p>
<ul>
<li><code>setup =</code>standard, <code>code = obj.fit(X)</code></li>
<li><code>setup =</code>standard, <code>code = obj.fit_transform(X)</code></li>
<li><code>setup =</code>standard<code>+ obj.fit(X)</code>, <code>code = obj.transform(X)</code></li>
</ul>
<h2>How much time were we&nbsp;wasting?</h2>
<p>Let&#8217;s say it takes 10 seconds. For every benchmark, we time the code by
running it 3 times. We run it once more to measure memory usage, once
more for <code>cProfile</code> and one last time for <code>line_profiler</code>. This is a
total of 6 times per benchmark. We need to multiply this by 2 again for
running on two datasets. So when benchmarking <code>NMF</code>, because we need to
fit before predicting, we do it 12 extra times. If a fit takes 5
seconds, this means one minute wasted on benchmarking just one
estimator. <em>Wouldn&#8217;t it be nice to <code>fit</code>, <code>fit_transform</code> and
<code>transform</code> in a&nbsp;sequence?</em></p>
<h2>Behind the&nbsp;scenes</h2>
<p>We made the <code>PythonBenchmark code</code> parameter also support getting a
sequence of strings, instead of just a string. On the database side,
every benchmark result entry gets an extra component in the primary key,
the number of the step it&nbsp;measures.</p>
<p>In the benchmark description files, nothing is&nbsp;changed:</p>
<p>[sourcecode lang=&#8221;python&#8221;]<br>
{<br>
&#8216;obj&#8217;: &#8216;<span class="caps">NMF</span>&#8217;,<br>
&#8216;init_params&#8217;: {&#8216;n_components&#8217;: 2},<br>
&#8216;datasets&#8217;: (&#8216;blobs&#8217;,),<br>
&#8216;statements&#8217;: (&#8216;fit_unsup&#8217;, &#8216;transform_unsup&#8217;, &#8216;fit_transform&#8217;)<br>
},<br>&nbsp;[/sourcecode]</p>
<p>But before, we would take the cartesian product of datasets and
statements, and build a <code>Benchmark</code> object for every pairing. Now, we
just pass the tuple as it is, and vbench is smart enough to do the right
thing.<br>
We avoided the extra calls to <code>fit</code> in a lot of benchmarks. The whole
suite now takes almost half the time to&nbsp;run!</p>
<p><em>Note:</em> This trick is currently hosted in the
<code>abstract_multistep_benchmarks</code> vbench branch in my&nbsp;fork.</p>
    </div><!-- /.entry-content -->
    <div class="comments">
      <h2>Comments !</h2>
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        var disqus_shortname = 'vene';
        var disqus_identifier = 'blog/the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks.html';
        var disqus_url = '//vene.ro/blog/the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks.html';
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//vene.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
      <noscript>Please enable JavaScript to view the comments.</noscript>
    </div>

  </article>
</section>
 </div>
<footer>
  <p>Powered by <a href="http://pelican.readthedocs.org">Pelican</a>.
  <a href="/privacy.html">Privacy policy</a>.</p>
</footer>
</div>
</body>
</html>